# Stefano_Project_Thesis
This is the repository for Stefano's project and thesis.

# Pilot project :heavy_check_mark:
* Machine learning to infer active open chromatin regions from transcription initiation events

#### Week 1, 2
* Familiarize with the problem and data
* Understand dREG input and output

#### Week 3 
* Implemented exploration and input profiles extraction (1 replicate) for ML models
* Implemented first ML models: random forest, lightGBM, SVM RBF
* Models evaluation

#### Week 4
* Implemented profiles extraction using all replicates
* Implemented cross validation
* Implemented two SVM RBF models: SVR + logistic regression and SVC
* Modified input data by filtering the negative set
* Assessed profile extraction and models performance on new input data

#### Week 5
* Implemented cross validation by chromosomes
* Tested the effect of increasing the size of the negative set 
* Improved evaluation
* Implemented removal of intra ATAC overlaps by rank (total CAGE scpre) approach 
* Assess the meaningfulness of the new input
* Tested the effect of using different filters on the negative set
* Added feature importance
* Implemented grid and random search for hyperparameters tuning

#### Week 6
* Added weight scalers (balanced by the classifier internal function, balanced by custom function, set by the user as hyperparameter) for both RF and LGBM 
* Added LGBM peformance evaluation during training (evaluation and plot of binary error, MCC, F1, TPR and TNR)
* Extensive test of the different weight scalers on three datasets (differing by the negative and positive samples size ratio: 0.5, 1, 3)
* Added seed values on all CV chromosomes split (fairer comparison between methods) and max number of CV iterations for grid and random search (speed up the search)

#### Week 7
* Enabled GPU for LGBM (issue: see warning during training) and SVM (ThunderSVM)
* Implemented prediction on test data for all models
* Polished the code

# Thesis project :checkered_flag:
Development of a machine learning tool to infer active open chromatin regions from transcription initiation events

#### Weeks 1 to 4
* Planning and reading relevant papers
* Set up conda environment to work in the server 
* Full optimization of random forest using random search
* Generated new input: 
    * Tested windows of size 302, 352, 402, 452, 502 (original), 602  
    * Generated new negative set using input vector with windows of 302 bp. The negative samples are generated by allowing partial overlaps with the ATAC positive regions but not with 100 bp around the central ATAC peak. All negative samples were added to the negative set (no sampling) to simulate real-case scenario, obtaining a dataset of size 267546 (TOT = 268K, Pos = 64k (24%), Neg = 204k)
* Implemented Bayesian optimization of random forest (scikit-optimize) and LightGBM (scikit-optimize, BayesianOptimization, HyperOpt), although class imbalanced required LGBM's positive class weigth to be manually tuned
* Implemented a simple 1D CNN

#### Weeks 5 to 9
* Implemented CV for CNN
* Implemented and tuned deep CNN obtaining better performance than LGBM model 
* Generated several new inputs: 
    * Use all replicates from all timepoints
    * Extracting the profiles from each replicate and merging them afterward (TP0: TOT = 479k, Pos = 159k (33%), Neg = 320k)
    * Applied smoothing and cubic spline (and visualization of the result)
    * Applied normalized strands subtraction (and visualization of the result)
    * Data augmentation by adding shifted positive profiles and flanking (to ATAC positive cores) shifted negative profiles. To increase variability the profiles of each replicates are shifted by different bp. The obtained data are almost balanced and the profiles have been more than doubled (TP0: TOT = 1001k, Pos = 472k (47%), Neg = 529k)
    * Applied data augmentation and normalized strands subtraction to all timepoints
    * Train chromosomes of TP 0 to 2 will be used as TRAIN set, test chromosomes of TP 0 to 2 will be used as SOFT TEST set, test chromosomes of TP 6 will be used as HARD TEST set
 * Model evaluation
    * LGBM feature importance for new imput 
    * Summary heatmap
    * PCA plots showing difference between timepoints, replicates, and chromosomes
    * Visualization of the probabilities predicted by the models (including the probabilities of TP, TN, FP, FN predictions)
    * Visualization of correctly and wrongly classified profiles (PCA and CAGE signal cumulative distribution)
* Cleaned and completely rearrenged R code. Set up conda environment to make it work on the server

#### Week 10, 11
* Implemented custom callbacks: 
    * Implement plotting function to monitor real performance on train and validation data
    * Training data is evaluated without active dropout and is not approximated with running average 
* Use checkpoint to save real best (val loss) epoch model (early stopping didn't work as expected)
* Compared learning curves with and without dropout (using the same initialized weigths)
* Implemented new training CV to save scaler and best epoch model at each iteration

#### Week 12
* Implemented prediction of new data both LGBM and CNN
* CNN hyperparameter tuning for training with full data (timepoints 0 to 2)

#### Week 13 to now
* Evaluated model on GM12878 Test (both ATAC and DNase extractions), and HeLa Test (both EGFP and Rrp40 experiments)
* Implemented genome wide prediction and visualization
* Investigated model interpretability (SHAP), and correctly and wrongly classified profiles
* Investigated the effect of removing potentially confounding profiles from the training set (1: profiles predicted with uncertainty, 2: wrong profiles predicted with certainty)
* Cleaned, commented, and rearrenged python code
* Automated the prediction pipeline into an intuitive and easy-to-use command line tool
* Wrote brief tool documentation

# Tool brief documentation :fire:
CAGE_tool attempts to infer potential active open chromatin regions from Cap Analysis of Gene Expression (CAGE) data. 

## Setup
The setup requires Anaconda to be installed, and to overcome a conflict between python and R packages, the tool uses two dedicated Anaconda environments, to which must be assigned a specific name.

### Download
Clone the repository and decompress the models:

```
$ for file in models/*.rar; do unrar e $file; done
```

### Instal Python environment

```
$ conda create -n cage_tool_py
$ conda activate cage_tool_py
$ conda install -c anaconda tensorflow-gpu
$ conda install -c anaconda pandas
$ conda install -c conda-forge lightgbm
$ conda install -c conda-forge keras
$ conda install scikit-learn
```

### Instal R environment

```
$ conda create -n cage_tool_r
$ conda activate cage_tool_r
$ conda install -c conda-forge r-base
```

Lunch R and install the following packages:

``` r
install.packages("argparse")
install.packages("tibble")
install.packages("dplyr")
install.packages("readr")
install.packages("forcats")
install.packages("ggplot2")
install.packages("tidyr")
install.packages("gridExtra")
install.packages("reshape2")
install.packages("RColorBrewer")
if (!requireNamespace("BiocManager", quietly=TRUE))
    install.packages("BiocManager")
BiocManager::install("GenomicRanges")
BiocManager::install("rtracklayer")
```

## Description
This tool allows the user to perform a genome-wide prediction of potential active Open Chromatin Regions (OCRs) or Transcriptional Regulatory Elements (TREs) from CAGE data. To achieve the forecast, it uses gradient boosting trees (default) or convolutional neural networks, which were trained on ~5 million CAGE profiles labeled using ATAC-Seq data. First, the tool scans the genome extracting the CAGE profiles of regions having a minimum transcriptional activity (2 TSS in at least one position). Then, it predicts the probability of the extracted profiles to be potential active TREs, and it generates different plots showing the results of the analysis (e.g., average shape of the predicted profiles, their distribution across the chromosomes, and the distribution of their total CAGE score). 

## Input and output

Input:
* `<CTSS_filename>.bed.gz` (or other formats supported by `rtracklayer::import()`)

Output: 
* `profiles_<filename>.csv`
* `profiles_<filename>_subtnorm.csv`
* `metadata_<filename>.csv`
* `tres_prediction_<filename>.csv`
* `tres_prediction_UCSC_track_<filename>.bed`
* Plots

The tool takes as input a CAGE Transcription Start Site (CTSS) file and it generates different plots and five tabular files: two files including the CAGE profiles of the extracted regions (`profiles_<filename>.csv` and `profiles_<filename>_subtnorm.csv`), one file including metadata information (`metadata_<filename>.csv`) showing their genomic coordinates (chromosome and start site), one file including the predictions (`tres_prediction_<filename>.csv`), and one file including the predicted scores ready to be visualized as UCSC Genome Browser track (`tres_prediction_UCSC_track_<filename>.bed`). It outputs two files containing the profiles because one file (`profiles_<filename>.csv`) includes profiles represented as vectors of concatenated CAGE scores from forward and reverse strands. This representation is helpful for intuitive visualization of the CAGE signal on the different strands. In contrast, the other file (`profiles_<filename>_subtnorm.csv`) includes the processed profiles used as input for the machine learning algorithm to perform the prediction. These profiles are obtained by performing a normalized subtraction of the CAGE score between forward and reverse strands, which allows capturing the shift in the intensity of the CAGE signal between the strands. 

## Usage
The user simply needs to specify the path of the CAGE input file using the flag `-i, --input_cage`, and the automated pipeline will generate the directories to store the results, scan the genome extracting profiles of 351 bp, perform and store the predictions and generate the plots. 

```
$ ./tool_master_script.sh -i <my_CAGE_input_file.bed.gz>
```

It is possible to add the flag `-h, --help` to get additional information about the correct usage of the tool and all available options:

```
$ ./tool_master_script.sh -h
CAGE_tool - Attempt to infer potential active open chromatin regions from CAGE data

Usage: CAGE_tool [-i] <file> [OPTIONS]...

Required:
  -i, --input_cage          specify the path for the input CAGE data

Options:
  -h, --help                display this help and exit
  -f, --filename_out        specify the name that will be assigned to the output files        default is 'my_tres_prediction'
  -o, --output_dir          specify the directory to store the output                         default is './'
  -s, --step                specify the frequency (bp) to scan the genome                     default is '5'
  -F, --format              specify the format of the CAGE input file                         default is 'gz'
  -a, --algorithm           specify the machine learning algorithm ('cnn' or 'lgbm')          default is 'lgbm'
  -M, --model_dir           specify the directories to load the model and the scaler          default is './models/'
  -m, --model_name          specify the filename of the model and the scaler to load          default is 'fit_on_timepoint_0_to_2_processed'
```

It is recommended to specify an output filename using the flag `-f, --filename_out`, and an output directory using the flag `-o, --output_dir`:

```
$ ./tool_master_script.sh -i <my_CAGE_input_file.bed.gz> -f <my_filename_as_output> -o <my_output_directory/>
```

By default, the tool scans genomic regions every 5 base pair, but the user can change this by adding an integer after the flag `-s, --step`:

```
$ ./tool_master_script.sh -i <my_CAGE_input_file.bed.gz> -f <my_filename_as_output> -o <my_output_directory/> -s <100>
```

By default, the format of the input CAGE file is 'gz', but that can be changed (e.g. to `bed`) by adding the flag `-F, --format`:

```
$ ./tool_master_script.sh -i <my_CAGE_input_file.bed> -f <my_filename_as_output> -o <my_output_directory/> -F <bed>
```

The user can also select the algorithm (LGBM or CNN) used for the prediction by adding `lgbm` or `cnn` after the flag `-a, --algorithm`, and can also use different trained models by adding the flag `-M, --model_dir`, which specify the model directory, and `-m, --model_name`, which set the model name.

```
$ ./tool_master_script.sh -i <my_CAGE_input_file.bed.gz> -f <my_filename_as_output> -o <my_output_directory/> -a <cnn> -M <my_model_directory/> -m <my_model_name>
```


